{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Gradient(Stocastic) descent from scraatch and sciket**"
      ],
      "metadata": {
        "id": "XUCbjih6xrwB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ioT7IguuwDHe"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X,y = load_diabetes(return_X_y=True)\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "HEAS0DcayM5H",
        "outputId": "d22b550c-b921-420f-8559-57477bf88cf7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(442, 10)\n",
            "(442,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "jf4uqpQLyeqQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg = LinearRegression()\n",
        "reg.fit(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "QWQ0KF0pyo1s",
        "outputId": "bf050403-7b42-4c91-e452-eb9c886fa1d5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = reg.predict(X_test)\n",
        "r2_score(y_test , y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Adnv_wd4zOqL",
        "outputId": "716b5014-25d1-46e1-be06-fe74e9ce142b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4526027629719195"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we create our own class\n",
        "\n",
        "class SGDRegressor:\n",
        "\n",
        "  def __init__(self , learning_rate = 0.01 , epochs = 100):\n",
        "    self.coef_ = None\n",
        "    self.intercept_ = None\n",
        "    self.lr = learning_rate\n",
        "    self.epochs = epochs\n",
        "\n",
        "  def fit(self , X_train , y_train):\n",
        "    #init our coefs\n",
        "    self.intercept_ = 0\n",
        "    self.coef_ = np.ones(X_train.shape[1])\n",
        "\n",
        "    for i in range(self.epochs):\n",
        "      for j in range(X_train.shape[0]):\n",
        "        idx = np.random.randint(0,X_train.shape[0])\n",
        "\n",
        "        y_hat = np.dot(X_train[idx] , self.coef_) + self.intercept_\n",
        "\n",
        "        intercept_der = -2 * (y_train[idx] - y_hat) ## dL/db = -2(y - mx)\n",
        "        self.intercept_ = self.intercept_ - (self.lr * intercept_der)\n",
        "\n",
        "        coef_der = -2 *np.dot((y_train[idx] - y_hat) , X_train[idx])\n",
        "        self.coef_ = self.coef_ - (self.lr * coef_der)\n",
        "\n",
        "      print(self.intercept_ , self.coef_)\n",
        "\n",
        "  def predict(self , X_test):\n",
        "    return np.dot(X_test , self.coef_) + self.intercept_\n",
        ""
      ],
      "metadata": {
        "id": "uCeNganczZFb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sgd = SGDRegressor(learning_rate= 0.01 , epochs= 50)\n"
      ],
      "metadata": {
        "id": "26gTaARf2enD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sgd.fit(X_train , y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wRxLKb1q3uDA",
        "outputId": "f96cd410-fa9b-4379-e14b-dc8c30e28fc6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "155.34568056017773 [ 4.52000976  1.34139576 15.86248315 13.91427963  8.46050705  6.80101479\n",
            " -8.03758737 13.34587035 17.30442459 10.27891178]\n",
            "143.6529476044728 [ 10.80307812   3.53570512  32.57775829  24.71542689  11.84701721\n",
            "   9.10946255 -18.96243024  25.56730244  31.58986389  22.37174466]\n",
            "150.3765018272124 [ 14.62591659   3.12540091  46.68469757  33.53163833  16.60338219\n",
            "  12.93198207 -28.62428176  35.96932488  45.93613802  31.36825336]\n",
            "139.9058568190634 [ 18.73597624   1.81685115  58.8835616   40.96011032  19.96111817\n",
            "  15.4133834  -36.48197189  45.860616    56.74768428  38.44359096]\n",
            "153.63734988834545 [ 22.09203675   1.24267392  71.74144027  51.40317498  22.79366762\n",
            "  17.37781771 -43.01700772  52.60583042  66.73917418  44.53962526]\n",
            "145.4648756426385 [ 25.33077942   1.62220254  82.19028752  58.9496487   25.45191638\n",
            "  18.94235118 -51.42711248  61.20867828  78.10770362  51.24504964]\n",
            "160.34346533834824 [ 29.09249712   0.2316682   94.84186142  67.98239426  27.10890093\n",
            "  19.36167632 -57.38879578  66.22881334  88.34016326  58.76366119]\n",
            "147.02185984098142 [ 30.24245554   0.821547   106.10132296  75.88255407  29.23563236\n",
            "  20.96217994 -65.14060295  74.2661761   98.08415918  66.70594718]\n",
            "153.95491009680194 [ 32.65363152  -1.42220392 115.21825478  83.05998502  31.89698384\n",
            "  22.58818534 -70.54352099  80.5636346  106.80943649  72.02340798]\n",
            "155.36413747286076 [ 35.306587    -2.37822033 124.77808742  91.87520044  32.70496392\n",
            "  21.41263395 -75.29678376  85.17929348 116.8226465   77.16190051]\n",
            "153.25207744563647 [ 37.51983158  -3.97993546 137.38953853  98.20308594  33.45777188\n",
            "  21.67274584 -82.0587481   91.86642314 125.01327376  82.01572449]\n",
            "151.16306352264345 [ 39.18843141  -4.7330968  147.20285337 105.09647376  34.82345335\n",
            "  22.3864596  -87.66008411  96.96977158 132.68325922  88.12401838]\n",
            "158.99084244201896 [ 42.52481577  -6.3899358  156.65429571 111.88400961  35.80382882\n",
            "  22.09394359 -92.40216911 101.12175382 141.37764425  94.03631507]\n",
            "150.47792281834177 [ 45.99710439  -7.95573848 165.92614331 119.81589298  37.20096879\n",
            "  21.10035122 -95.81640341 105.11919612 150.59039581  99.67256787]\n",
            "155.54239099242784 [  47.79920257  -11.81403216  175.49106143  126.22119655   37.65440183\n",
            "   20.75429039 -100.77707053  110.0207898   158.04902297  103.24373825]\n",
            "147.68089431854636 [  50.3750928   -11.31503021  182.51133076  131.34286416   38.26499046\n",
            "   21.08503243 -107.16284147  115.69311114  165.00639561  105.72645317]\n",
            "160.84876510270703 [  51.69399586  -13.45196415  191.7935972   137.93293999   37.16275978\n",
            "   18.80443066 -111.4837121   118.75601775  171.9622356   108.34342628]\n",
            "144.3430577548503 [  51.45605909  -15.43299223  199.19987285  141.43896658   34.61087085\n",
            "   16.4353768  -117.88087251  123.18029015  177.18074512  111.91921871]\n",
            "153.31460072039533 [  53.26539707  -17.15106676  205.95264156  148.55372594   33.81868055\n",
            "   13.66484806 -120.35419768  124.46148216  183.52727334  116.637191  ]\n",
            "144.8113998431637 [  55.78818255  -18.3377903   212.72986363  153.0637149    33.45044663\n",
            "   12.88268386 -124.30691516  127.38536041  188.95542633  120.0429823 ]\n",
            "160.72602619897663 [  58.30278699  -21.03060827  219.54195624  158.88258048   35.00598536\n",
            "   13.66980205 -126.73946856  130.17006178  194.49363231  123.43855851]\n",
            "151.56616822018066 [  60.5390947   -21.69239657  226.76677998  164.13078741   37.30183749\n",
            "   15.44755634 -130.30181195  134.77891918  200.63872657  125.3466518 ]\n",
            "147.43225910906344 [  60.3774048   -25.21803267  233.95936969  168.09901383   36.53700345\n",
            "   14.049761   -132.33438481  135.74296004  204.69614826  127.2486203 ]\n",
            "143.24670351026123 [  61.13616911  -26.15695697  240.51690808  171.90368638   36.29557888\n",
            "   13.50322584 -136.10949237  139.37706695  209.37529527  129.95501856]\n",
            "154.78637713956655 [  62.00301337  -29.37397129  246.374976    176.39533919   35.44007994\n",
            "   11.66572354 -138.11955137  140.60894485  213.69014131  132.06803786]\n",
            "154.4929795120596 [  62.02733129  -33.02712587  252.17062345  180.28609586   33.17656906\n",
            "    8.51362224 -140.54405604  140.88302475  217.53983129  133.15077322]\n",
            "154.48001613727558 [  62.70435506  -36.41548957  258.57590619  183.98349589   34.14581932\n",
            "    9.0194653  -143.41608585  143.48092067  222.48585868  136.39826327]\n",
            "142.39897663477706 [  63.46549373  -37.91269754  262.72746626  187.82632191   32.21387026\n",
            "    7.13598791 -145.27254899  144.06774867  224.69737765  137.27055969]\n",
            "154.75245301151236 [  62.67292909  -40.01725435  270.37695002  190.33278654   32.89534076\n",
            "    7.3052421  -148.77215313  147.62703825  229.57087605  140.76734462]\n",
            "150.8533855384339 [  63.02224878  -40.91416525  276.77713674  193.06425842   30.99895219\n",
            "    5.96735669 -152.29016923  149.62134051  231.97845296  141.63753325]\n",
            "153.66259719693986 [  63.14123292  -43.40785489  281.4895128   196.54067443   28.75683005\n",
            "    2.69350303 -153.47825512  149.33546016  235.16044082  142.37750533]\n",
            "148.0913932322161 [  62.14005933  -45.82332744  286.50227327  198.84434376   28.41068135\n",
            "    2.36851853 -156.76004124  152.21170972  238.97852244  143.08477494]\n",
            "150.7001315192697 [ 6.21202247e+01 -4.75978991e+01  2.92964465e+02  2.02389116e+02\n",
            "  2.64831208e+01  1.14833740e-01 -1.58941627e+02  1.53260497e+02\n",
            "  2.41666751e+02  1.43117613e+02]\n",
            "148.64398793546647 [  61.95786222  -51.31508618  298.10848439  204.98134619   25.01646325\n",
            "   -3.03254777 -160.16674829  152.98059054  246.31076164  144.22104092]\n",
            "153.41474921251327 [  62.55124107  -53.47677294  300.63167425  209.93155391   25.15478444\n",
            "   -3.2675686  -160.93044883  153.83353266  248.58957101  146.8330025 ]\n",
            "153.52353201687242 [  62.41304455  -58.08860479  306.13162575  213.41125527   24.52451127\n",
            "   -5.46296299 -160.20632151  152.39850818  252.08565537  147.18602708]\n",
            "152.468296549632 [  62.31657408  -60.3313103   311.39147144  218.07214187   23.06725626\n",
            "   -8.19955347 -161.74312697  152.50349793  256.31531107  149.74117281]\n",
            "157.93194059571385 [  61.45002379  -63.95642926  315.34149481  221.8486547    21.49549154\n",
            "  -10.42586692 -162.09083703  151.74540195  258.14117702  148.44897087]\n",
            "151.31426673091013 [  61.1321508   -65.84553776  319.29230602  223.87924939   17.78713381\n",
            "  -14.87690618 -163.31869299  150.60342765  260.13343354  147.77503017]\n",
            "155.8269640633018 [  59.49766278  -68.13707952  323.931396    224.68033108   18.00470393\n",
            "  -14.67105353 -165.0342879   152.1645568   262.8909138   148.92637653]\n",
            "149.58490192916895 [  58.23124629  -71.45452068  327.24411324  226.58817555   14.98470096\n",
            "  -18.71996102 -166.04371277  150.96886885  265.57263361  147.74603867]\n",
            "150.0275669136476 [  57.76368992  -73.67424895  328.97881596  230.16162865   12.6620521\n",
            "  -22.36726594 -165.96655354  149.35789188  267.844138    147.78730985]\n",
            "144.2634135877051 [  56.11472949  -75.81996576  332.07362453  231.88821549   10.84686266\n",
            "  -24.19691986 -168.46505599  150.46014093  269.94611346  147.89157725]\n",
            "147.74739176904737 [  57.81828281  -77.82873652  336.58009645  235.1409133     8.88817543\n",
            "  -27.03179296 -168.94249426  149.3293491   272.41718132  148.59938698]\n",
            "157.6991153448149 [  58.81317313  -81.22520865  340.92672473  237.93698111    7.09040345\n",
            "  -29.20597614 -169.92690147  148.9288092   274.07241815  149.56330554]\n",
            "151.76852571868105 [  57.62270247  -82.97253872  343.27327804  241.25564161    3.46891117\n",
            "  -34.48811738 -169.60403023  146.64452572  276.47400628  149.35946286]\n",
            "145.71477741731493 [  58.42006204  -85.72678477  349.33045783  243.87110269    1.6119556\n",
            "  -36.73728257 -171.73567512  147.76765228  279.41941702  151.50081601]\n",
            "152.91327255793712 [  60.10403378  -86.73937765  353.80293406  246.91265862    1.41610903\n",
            "  -36.97413997 -173.71518812  149.14180924  281.77540425  154.20207748]\n",
            "156.30562900737567 [ 6.06064924e+01 -8.76192386e+01  3.56789534e+02  2.49144374e+02\n",
            "  6.13516414e-02 -3.78520059e+01 -1.75186123e+02  1.49655821e+02\n",
            "  2.82777444e+02  1.54205751e+02]\n",
            "154.42577303226386 [  60.16931856  -88.32727795  359.06674638  251.0885588    -2.6486972\n",
            "  -41.08667923 -176.38839018  148.44573763  284.52989125  154.03783658]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = sgd.predict(X_test)\n",
        "r2_score(y_test , y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "EHkICedD3w_9",
        "outputId": "7df0e925-de06-41be-cada-deeaa7f24cdb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4458736232257886"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# y_pred"
      ],
      "metadata": {
        "id": "vreggNRX5A7n"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient(Minibatch - GradinetDescent)"
      ],
      "metadata": {
        "id": "8d3vpZUn6xx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "hRcG9ebN5ML7"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X,y = load_diabetes(return_X_y=True)\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNysXN2C7CpK",
        "outputId": "21e0e839-288d-4e68-b060-b37e3d10f794"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(442, 10)\n",
            "(442,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "2XmDLOwS7Ge4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LinearRegression()\n",
        "lr.fit(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "0s0Q6D1X92Je",
        "outputId": "46e33126-b768-480f-9a34-f113afc481b9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lr.coef_)\n",
        "print(lr.intercept_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDrALAo594fj",
        "outputId": "7119ceb4-237b-454e-f167-951833de301f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  37.90402135 -241.96436231  542.42875852  347.70384391 -931.48884588\n",
            "  518.06227698  163.41998299  275.31790158  736.1988589    48.67065743]\n",
            "151.34560453985995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = lr.predict(X_test)\n",
        "r2_score(y_test , y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31wTxkXn-viy",
        "outputId": "bae37df6-21e0-4ae0-c0d8-3dca131a3728"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4526027629719195"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class MBGDRegressor:\n",
        "  def __init__(self , batch_size , learning_rate = 0.01 , epochs = 100):\n",
        "    self.coef_ = None\n",
        "    self.intercept_ = None\n",
        "    self.lr = learning_rate\n",
        "    self.epochs = epochs\n",
        "    self.batch_size = batch_size\n",
        "  def fit(self , X_train , y_train):\n",
        "    #init our coefs\n",
        "    self.intercept_ = 0\n",
        "    self.coef_ = np.ones(X_train.shape[1])\n",
        "\n",
        "    for i in range(self.epochs):\n",
        "\n",
        "      for j in range(int(X_train.shape[0]/self.batch_size)):\n",
        "        idx = random.sample(range(X_train.shape[0]),self.batch_size)\n",
        "        y_hat = np.dot(X_train[idx] , self.coef_) + self.intercept_\n",
        "        intercept_der = -2*np.mean((y_train[idx] - y_hat))\n",
        "        self.intercept_ = self.intercept_ - (self.lr * intercept_der)\n",
        "\n",
        "        coef_der = -2*np.dot((y_train[idx] - y_hat) , X_train[idx])\n",
        "        self.coef_ = self.coef_ - (self.lr * coef_der)\n",
        "    print(self.intercept_ , self.coef_)\n",
        "\n",
        "  def predict(self , X_test):\n",
        "    return np.dot(X_test , self.coef_) + self.intercept_"
      ],
      "metadata": {
        "id": "lAyrkWev99Rl"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mbr = MBGDRegressor(batch_size= int(X_train.shape[0]/10) , learning_rate= 0.01 , epochs= 50)"
      ],
      "metadata": {
        "id": "wPuFLB7-AnJ9"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mbr.fit(X_train , y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMcRKZcgB4q4",
        "outputId": "271412a8-63f9-4dba-8972-be6a0424f885"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "151.95294967538885 [  65.21699688  -84.58631169  364.718568    260.08450902   -3.56875618\n",
            "  -39.34520595 -181.35677377  145.18016909  287.54673702  151.80969342]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r2_score(y_test , y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvqeH2q4DaWj",
        "outputId": "9267be63-42a3-4eab-96a5-0922a5ffd39a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4526027629719195"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JQ6-EglpD5Yc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}